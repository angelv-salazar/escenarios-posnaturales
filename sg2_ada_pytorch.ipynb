{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sg2-ada-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GwPrEVh5coPf"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelv-salazar/escenarios-posnaturales/blob/main/sg2_ada_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZkTQZc7cMWN"
      },
      "source": [
        "# Entrenamiento personalizado: StyleGan2-ADA\n",
        "\n",
        "En este cuaderno, realizaremos el aprendizaje por transferencia con StyleGAN2 y conjuntos de datos personalizados.\n",
        "\n",
        "Esto significa que no entrenaremos a la red GAN con nuestras imágenes desde cero (ya que toma alrededor de dos semanas) pero usaremos el modelo ya entrenado en las otras imágenes como punto de partida. Reducirá el tiempo de entrenamiento a aproximadamente 10 horas al omitir las primeras etapas donde la red neuronal aprende características de bajo nivel de imágenes que son casi las mismas para cualquier tipo de imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOgc3AOiY6iU",
        "cellView": "form"
      },
      "source": [
        "#@title Montar Google Drive\n",
        "#@markdown Monte Google Drive para cargar modelos previamente entrenados y guardar los resultados.\n",
        "\n",
        "#@markdown Después de ejecutar esta celda, obtendrá el enlace. Haga click en el enlace, otorgue acceso a su Drive y copie el código de autenticación.\n",
        "\n",
        "#@markdown Pegue el código en la entrada a continuación y presione Enter\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6nP8w7IZDpb",
        "cellView": "form"
      },
      "source": [
        "#@title Instalación\n",
        "#@markdown StyleGAN2-ADA será instalada en su Google Drive para acelerar el proceso de entrenamiento.\n",
        "\n",
        "#@markdown Ejecute esta celda. Si ya ha instalado el repositorio, se omitirá el proceso de instalación y actualizará el directorio del repositorio. Si no lo ha instalado, instalará todos los archivos necesarios.\n",
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/colab-sg2-ada-pytorch\"):\n",
        "    %cd \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n",
        "elif os.path.isdir(\"/content/drive/\"):\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/\"\n",
        "    !mkdir colab-sg2-ada-pytorch\n",
        "    %cd colab-sg2-ada-pytorch\n",
        "    !git clone https://github.com/dvschultz/stylegan2-ada-pytorch\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU -O /content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/pretrained/wikiart.pkl\n",
        "else:\n",
        "    !git clone https://github.com/dvschultz/stylegan2-ada-pytorch\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    %cd pretrained\n",
        "    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU\n",
        "    %cd ../\n",
        "\n",
        "!pip install ninja opensimplex\n",
        "\n",
        "%cd \"/content/drive/My Drive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n",
        "!git config --global user.name \"test\"\n",
        "!git config --global user.email \"test@test.com\"\n",
        "!git fetch origin\n",
        "!git pull\n",
        "!git stash\n",
        "!git checkout origin/main -- train.py generate.py legacy.py closed_form_factorization.py flesh_digression.py apply_factor.py README.md calc_metrics.py training/stylegan2_multi.py training/training_loop.py util/utilgan.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MgOcCseZqlA",
        "cellView": "form"
      },
      "source": [
        "#@title Preparación de Datos\n",
        "#@markdown Directorio de entrada de Imágenes\n",
        "input_dir = '' #@param {type: \"string\"}\n",
        "#@markdown Ruta al archivo *zip* donde se almacenará el *Dataset* convertido. Usted debe crearlo la primera vez.\n",
        "dataset_file = '' #@param {type: \"string\"}\n",
        "\n",
        "if not dataset_file.endswith('.zip'):\n",
        "  dataset_file += '.zip'\n",
        "\n",
        "!python dataset_tool.py --source {input_dir} --dest {dataset_file}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E25JTmDbZX1z",
        "cellView": "form"
      },
      "source": [
        "#@title Entrenamiento de Modelo Personalizado\n",
        "\n",
        "#@markdown Ruta al archivo *zip* del *Dataset*\n",
        "dataset = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Para el aprendizaje por transferencia, configúrelo en **ffhq256**, **ffhq512** o **ffhq1024** de acuerdo con la resolución de sus imágenes.\n",
        "#@markdown Si desea reanudar el proceso de capacitación, proporcione la ruta a su último archivo *.pkl*\n",
        "resume_from = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#don't edit this unless you know what you're doing :)\n",
        "!python train.py --outdir ./results --snap=1 --cfg='11gb-gpu' --data={dataset} --aug=noaug --mirror=False --mirrory=False --metrics=None --resume={resume_from}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwPrEVh5coPf"
      },
      "source": [
        "### Mientras se está entrenando...\n",
        "**Una vez que la celda anterior se esté ejecutando, ¡debería estar entrenando!**\n",
        "\n",
        "¡No cierre esta pestaña! Colab debe estar abierto y en funcionamiento para poder seguir entrenando.\n",
        "\n",
        "Cada 40 minutos más o menos debería añadirse una nueva línea a su salida, indicando que todavía está entrenando. Dependiendo de su configuración de `snapshot_count`, debería ver la carpeta de resultados (`/content/drive/MyDrive/colab-sg2-ada/stylegan2-ada/results`) en su carpeta de Google drive llenándose con ambas muestras (`fakesXXXXXx.jpg`) y *model weights* (pesos del modelo) (`network-snapshot-XXXXXX.pkl`). Vale la pena mirar las muestras mientras se entrena, pero no se preocupe demasiado por cada muestra individual.\n",
        "\n",
        "Una vez que Colab se apaga, puede volver a conectarse en el alojamiento y volver a ejecutar cada celda de arriba a abajo. Asegúrese de actualizar la ruta `resume_from` para continuar entrenando desde el último modelo."
      ]
    }
  ]
}